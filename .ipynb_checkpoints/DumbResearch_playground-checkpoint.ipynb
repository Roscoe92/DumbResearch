{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "dcba66ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string: unmatched '[' (2756192985.py, line 539)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[274], line 539\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f'Now looking at the websites of your competitor set {competitor_set['Website']}')\u001b[0m\n\u001b[0m                                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m f-string: unmatched '['\n"
     ]
    }
   ],
   "source": [
    "import selenium.webdriver as webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import time\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from urllib.parse import urlparse\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from webdriver_manager.core.os_manager import ChromeType\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "from io import StringIO\n",
    "import subprocess\n",
    "import shutil\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "import time\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import time\n",
    "\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "def get_chromium_version() -> str:\n",
    "    try:\n",
    "        result = subprocess.run(['chromium', '--version'], capture_output=True, text=True)\n",
    "        version = result.stdout.split()[1]\n",
    "        return version\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "def get_chromedriver_version() -> str:\n",
    "    try:\n",
    "        result = subprocess.run(['chromedriver', '--version'], capture_output=True, text=True)\n",
    "        version = result.stdout.split()[1]\n",
    "        return version\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "def get_chromedriver_path() -> str:\n",
    "    return shutil.which('chromedriver')\n",
    "\n",
    "def get_webdriver_options(headless=False):\n",
    "    options = Options()\n",
    "    \n",
    "    if headless:\n",
    "        # The newer headless argument is \"--headless=new\" for Chrome 109+\n",
    "        # If you experience compatibility issues, fallback to \"--headless\"\n",
    "        options.add_argument(\"--headless=new\")\n",
    "\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--disable-features=NetworkService\")\n",
    "    options.add_argument(\"--window-size=1920x1080\")\n",
    "    options.add_argument(\"--disable-features=VizDisplayCompositor\")\n",
    "    options.add_argument('--ignore-certificate-errors')\n",
    "    return options\n",
    "\n",
    "def get_webdriver_service():\n",
    "    service = Service(\n",
    "        executable_path=get_chromedriver_path()\n",
    "    )\n",
    "    return service\n",
    "\n",
    "def run_selenium(domain, headless=False):\n",
    "    \"\"\"\n",
    "    Attempts to fetch the HTML content of `domain` using Selenium.\n",
    "    If headless=True, runs in headless mode; otherwise, opens a visible browser window.\n",
    "    \"\"\"\n",
    "    html_content = None\n",
    "\n",
    "    options = get_webdriver_options(headless=headless)\n",
    "    service = get_webdriver_service()\n",
    "\n",
    "    with webdriver.Chrome(options=options, service=service) as driver:\n",
    "        try:\n",
    "            driver.get(domain)\n",
    "            time.sleep(2)  # Give the page time to load\n",
    "            html_content = driver.page_source\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while fetching {domain} in headless={headless} mode: {e}\")\n",
    "\n",
    "    return html_content\n",
    "\n",
    "def extract_body_content(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    body_content = soup.body\n",
    "    if body_content:\n",
    "        return str(body_content)\n",
    "    return \"\"\n",
    "\n",
    "def clean_body_content(body_content):\n",
    "    soup = BeautifulSoup(body_content,'html.parser')\n",
    "\n",
    "    for script_or_style in soup(['script', 'style']):\n",
    "        script_or_style.extract()\n",
    "\n",
    "    cleaned_content = soup.get_text(separator='\\n')\n",
    "    cleaned_content = '\\n'.join(\n",
    "        line.strip() for line in cleaned_content.splitlines() if line.strip()\n",
    "        )\n",
    "    return cleaned_content\n",
    "\n",
    "def split_dom_content(dom_content, max_length = 13000):\n",
    "    return [\n",
    "        dom_content[i : i + max_length] for i in range(0,len(dom_content), max_length)\n",
    "    ]\n",
    "\n",
    "def is_valid_url(url):\n",
    "    parsed = urlparse(url)\n",
    "    return all([parsed.scheme, parsed.netloc])  # Checks for scheme (http/https) and netloc (domain)\n",
    "\n",
    "\n",
    "def choose_links(links):\n",
    "    print(\"Here are the links to explore:\\n\")\n",
    "    for i, link in enumerate(links):\n",
    "        print(f\"{i}: {link}\")\n",
    "    \n",
    "    # Example input: \"0,2\"\n",
    "    user_input = input(\"\\nSelect the indexes of links you want to explore, separated by commas:\\n> \")\n",
    "    \n",
    "    # Convert the input string into a list of integers\n",
    "    indexes = [int(x.strip()) for x in user_input.split(\",\") if x.strip().isdigit()]\n",
    "    \n",
    "    chosen_links = [links[i] for i in indexes if i < len(links)]\n",
    "    return chosen_links\n",
    "\n",
    "\n",
    "def get_all_links(domain):\n",
    "    links_to_visit = []\n",
    "    try:\n",
    "        html = run_selenium(domain)\n",
    "        time.sleep(5)\n",
    "\n",
    "        # If run_selenium returned None, bail out early:\n",
    "        if html is None:\n",
    "            print(f\"Error: No HTML returned from run_selenium for '{domain}'\")\n",
    "            return links_to_visit\n",
    "        \n",
    "        # save content\n",
    "        body_content = extract_body_content(html)  # Extract body content\n",
    "        cleaned_content = clean_body_content(body_content)  # Clean the content\n",
    "        \n",
    "        #pull respective links\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        for a_tag in soup.find_all('a', href=True):\n",
    "            # Resolve relative URLs\n",
    "            full_url = urljoin(domain, a_tag['href'])\n",
    "            links_to_visit.append(full_url)\n",
    "        \n",
    "\n",
    "    except Exception as e:\n",
    "        # Refer to the domain (which is always defined), not full_url\n",
    "        print(f\"Error visiting domain '{domain}': {e}\")\n",
    "\n",
    "    return links_to_visit, cleaned_content\n",
    "\n",
    "def filter_urls_by_stem(stem_url, url_list):\n",
    "    \"\"\"\n",
    "    Compares each URL in url_list to stem_url.\n",
    "    If a URL starts with the stem_url, it's added to a matches list.\n",
    "    \n",
    "    :param stem_url: A string representing the 'stem' portion of the URL.\n",
    "    :param url_list: A list of full URLs to check against the stem URL.\n",
    "    :return: A list of URLs that match the stem URL.\n",
    "    \"\"\"\n",
    "    matches = []\n",
    "    for random_url in url_list:\n",
    "        # Simple check: does the random_url begin with stem_url?\n",
    "        if random_url.startswith(stem_url) and random_url not in matches and random_url != stem_url:\n",
    "            matches.append(random_url)\n",
    "    return matches\n",
    "\n",
    "def preprocess(chosen_links, depth=5):\n",
    "    start_time = time.time()  # Record the start time\n",
    "\n",
    "    # We’ll store all the link expansions here\n",
    "    link_library = {}\n",
    "    # We’ll store the body/content here. Key = URL, Value = text content\n",
    "    content_dict_master = {}\n",
    "\n",
    "    link_counter = 1\n",
    "\n",
    "    for link in chosen_links:\n",
    "        content_dict_sub = {}\n",
    "        link_set = set()\n",
    "\n",
    "        # 1) Get sub_links and sub_content for this chosen link\n",
    "        sub_links, sub_content = get_all_links(link)\n",
    "        # Store the content for the chosen link\n",
    "        content_dict_sub[link] = sub_content\n",
    "\n",
    "        # 2) Filter sub_links based on the stem\n",
    "        first_pass = filter_urls_by_stem(link, sub_links)\n",
    "        link_set.update(first_pass)\n",
    "\n",
    "        frontier = set(first_pass)\n",
    "\n",
    "        # 3) Expand up to the specified depth\n",
    "        for depth_level in range(depth):\n",
    "            next_frontier = set()\n",
    "            counter = 0\n",
    "\n",
    "            for current_link in frontier:\n",
    "                counter += 1\n",
    "\n",
    "                # Get the link list and content for each link in the frontier\n",
    "                current_links, current_content = get_all_links(current_link)\n",
    "\n",
    "                # Store the content in our dictionary\n",
    "                content_dict_sub[current_link] = current_content\n",
    "\n",
    "                # Filter the newly fetched links by the stem\n",
    "                new_links = set(filter_urls_by_stem(current_link, current_links))\n",
    "\n",
    "                # Filter out links we already visited\n",
    "                new_links -= link_set\n",
    "\n",
    "                # Update link_set and next_frontier\n",
    "                link_set.update(new_links)\n",
    "                next_frontier.update(new_links)\n",
    "\n",
    "                print(\n",
    "                    f'Processing {current_link}, '\n",
    "                    f'{counter} out of {len(frontier)} links in depth level {depth_level} '\n",
    "                    f'for {link}, {link_counter} out of {len(chosen_links)} selected links'\n",
    "                )\n",
    "\n",
    "            frontier = next_frontier\n",
    "\n",
    "        content_dict_master[link] = content_dict_sub\n",
    "        link_library[link] = list(link_set)\n",
    "        link_counter += 1\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"\\nPreprocess finished in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    # If desired, return both the link expansion results AND the content dictionary\n",
    "    return link_library, content_dict_master\n",
    "\n",
    "def preprocess_content(content_dict):\n",
    "    master_dict = {}\n",
    "    for key in content_dict.keys():\n",
    "        master_dict[key] = ''.join(content_dict[key].values())\n",
    "    return master_dict\n",
    "\n",
    "def run_chatgpt(prompt, model = \"gpt-3.5-turbo\"):\n",
    "    client = OpenAI(\n",
    "        api_key=os.environ.get(\"OPENAI_API_KEY\"),  # This is the default and can be omitted\n",
    "    )\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "       {\"role\": \"system\", \"content\": \"You are an advanced data extraction assistant.\"},\n",
    "       {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.0  # For deterministic responses\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def first_pass_with_chatGPT(dom_chunks, parse_description):\n",
    "    \"\"\"\n",
    "    Sends chunks of website content to OpenAI's GPT API for parsing based on a description.\n",
    "    \"\"\"\n",
    "\n",
    "    # Loop through chunks and get responses\n",
    "    parsed_results = []\n",
    "    for i, chunk in enumerate(dom_chunks, start=1):\n",
    "        template = (\n",
    "            f'You are tasked with extracting specific information from the following text content: {chunk}.'\n",
    "            'Please follow these instructions carefully: \\n\\n'\n",
    "            f' 1. ** Extract Information** : Only extract the information that directly matches the provided description {parse_description}'\n",
    "            ' 2. ** No Extra Content** : Do not include any additional text, comments or explanations in your response.'\n",
    "            ' 3. ** Empty Response** : If no information matches the description return to an empty string'\n",
    "            ' 4. ** Direct Data** : Your response should contain only data that is explicitly requested, with no other text.'\n",
    "            ' 5. ** Format** : **Single Table**: Output exactly one table, no extra lines or text.'\n",
    "                            '  - Use semicolons (`;`) to separate columns.'\n",
    "                            '  - Properly quote cells with (\"\") if they contain semicolons or commas.'\n",
    "                            '  - If a cell has no data, use `empty`.'\n",
    "            )\n",
    "        prompt = template\n",
    "        print(f\"Processing chunk {i}/{len(dom_chunks)}...\")\n",
    "\n",
    "        try:\n",
    "            response = run_chatgpt(prompt)\n",
    "            parsed_results.append(response.choices[0].message.content)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing chunk {i}: {e}\")\n",
    "            parsed_results.append(\"\")  # Append an empty string if there's an error\n",
    "\n",
    "    initial_result = \"\\n\".join(parsed_results)\n",
    "\n",
    "    return initial_result\n",
    "\n",
    "def parse_semicolon_csv(llm_output):\n",
    "    \"\"\"\n",
    "    Extracts table data from LLM output (potentially wrapped in ```csv code fences),\n",
    "    dynamically handles multiple delimiters, and ensures the resulting DataFrame has multiple columns.\n",
    "    \n",
    "    :param llm_output: The text output from the LLM containing tabular data.\n",
    "    :param delimiters: List of possible delimiters to handle, e.g., [\",\", \";\", \"\\t\", \"|\"].\n",
    "                       Defaults to common delimiters.\n",
    "    :return: A pandas DataFrame containing the parsed table data.\n",
    "    \"\"\"\n",
    "    # Default delimiters if none are provided\n",
    "    if delimiters is None:\n",
    "        delimiters = [\",\", \";\", \"\\t\", \"|\"]\n",
    "    \n",
    "    # 1) Extract the CSV text from code fences, if present\n",
    "    pattern = r\"```csv\\n(.*?)```\"\n",
    "    match = re.search(pattern, llm_output, flags=re.DOTALL | re.IGNORECASE)\n",
    "\n",
    "    if match:\n",
    "        csv_text = match.group(1).strip()\n",
    "    else:\n",
    "        # If no fenced block found, assume entire output is the CSV\n",
    "        csv_text = llm_output.strip()\n",
    "\n",
    "    # 2) Basic cleanup: remove trailing spaces or lines\n",
    "    lines = [line.strip() for line in csv_text.splitlines() if line.strip()]\n",
    "    csv_text = \"\\n\".join(lines)\n",
    "\n",
    "    # 3) Try parsing the CSV with each delimiter\n",
    "    for delimiter in delimiters:\n",
    "        try:\n",
    "            # Attempt to parse the text into a DataFrame\n",
    "            df = pd.read_csv(\n",
    "                StringIO(csv_text),\n",
    "                sep=delimiter,\n",
    "                engine=\"python\",\n",
    "                quotechar='\"',\n",
    "                on_bad_lines=\"skip\"  # Skip lines that don't match columns\n",
    "            )\n",
    "            # Check if the resulting DataFrame has more than one column\n",
    "            if df.shape[1] > 1:\n",
    "                break\n",
    "        except Exception:\n",
    "            # Ignore errors and try the next delimiter\n",
    "            continue\n",
    "    else:\n",
    "        # If none of the delimiters work, raise an error\n",
    "        raise ValueError(\n",
    "            \"Could not parse the table data with any of the specified delimiters or the result only has one column.\"\n",
    "        )\n",
    "    \n",
    "    # 4) Remove empty and unnamed columns\n",
    "    df.dropna(axis=\"columns\", how=\"all\", inplace=True)\n",
    "    df = df.loc[:, ~df.columns.str.contains(\"^Unnamed\")]\n",
    "\n",
    "    # 5) Clean column names\n",
    "    df.columns = [col.strip('\" ').strip() for col in df.columns]\n",
    "\n",
    "    # 6) Reset the index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def scrape_to_df(content_dict,parse_description):\n",
    "    start_time = time.time()\n",
    "    outputs = {}\n",
    "    master_dict = preprocess_content(content_dict)\n",
    "    counter = 0\n",
    "    for key in master_dict:\n",
    "        counter += 1\n",
    "        print(f'Processing {key}, {counter} out of {len(master_dict.keys())} datasets to process.')\n",
    "        dom_content = master_dict[key]\n",
    "        dom_chunks = split_dom_content(dom_content)\n",
    "        csv_output = first_pass_with_chatGPT(dom_chunks,parse_description)\n",
    "        outputs[key] = parse_semicolon_csv(csv_output)\n",
    "    end_time = time.time()\n",
    "    print(f\"\\nParsing scrape results finished in {end_time - start_time:.2f} seconds\")\n",
    "    return outputs\n",
    "\n",
    "def run_research(website,parse_description):\n",
    "    links,content = preprocess(website)\n",
    "    output = scrape_to_df(content,parse_description)\n",
    "    return output\n",
    "\n",
    "def select_topics():\n",
    "    def is_valid_url(url):\n",
    "        pattern = re.compile(r'^(https?:\\/\\/)?([\\w.-]+)+(:\\d+)?(\\/[\\w._-]*)*\\/?$')\n",
    "        return re.match(pattern, url)\n",
    "\n",
    "    website_input = input(\"\\nPlease paste the websites you'd like to explore, separated by commas: \")\n",
    "    if not website_input.strip():\n",
    "        print(\"No websites entered. Please try again.\")\n",
    "        return []\n",
    "\n",
    "    websites = [str(x.strip().lower().rstrip(\"/\")) for x in website_input.split(\",\") if x.strip()]\n",
    "    valid_websites = [x for x in websites if is_valid_url(x)]\n",
    "\n",
    "    if len(valid_websites) == 0:\n",
    "        print(\"No valid websites provided.\")\n",
    "        return []\n",
    "\n",
    "    print(f\"Websites selected: {', '.join(valid_websites)}\")\n",
    "    return valid_websites\n",
    "\n",
    "def user_selects(players = None):\n",
    "    if players is None:\n",
    "        domains = select_topics()\n",
    "    else:\n",
    "        domains = players.tolist() if isinstance(players, pd.Series) else players\n",
    "    domain_links = {}\n",
    "    for domain in domains:\n",
    "        initial_links, initial_content = get_all_links(domain)\n",
    "        domain_links[domain] = choose_links(initial_links)\n",
    "    return domain_links\n",
    "\n",
    "def user_task():\n",
    "    user_input = input('\\nPlease let DumbResearch know:\\n1. What web content it is looking at \\n2. What columns you would like your research output table to have \\n\\nSee example below: \\n\"These are the solutions offered by a german cyber security player (input is provided in German), please provide a table or tables that list the respective products / solutions with important information on the respective products e.g. their descriptions, features, target customers, KPIs\"\\n')\n",
    "    return user_input\n",
    "\n",
    "def initialize_dumbresearch(players = None):\n",
    "    if players is not None and not isinstance(players, (list, pd.Series)):\n",
    "        raise ValueError(\"`players` must be a list or Pandas Series of URLs\")\n",
    "    domains_selected = user_selects(players)\n",
    "    parse_description = user_task()\n",
    "    return domains_selected, parse_description\n",
    "\n",
    "def dumbresearch_workflow(players = None):\n",
    "    domains, parse_description = initialize_dumbresearch(players)\n",
    "    print(domains)\n",
    "    outputs = {}\n",
    "    for key in domains.keys():\n",
    "        links, content = preprocess(domains[key])\n",
    "        output = scrape_to_df(content, parse_description)\n",
    "        outputs[key] = output\n",
    "    return outputs\n",
    "\n",
    "def find_competitors():\n",
    "    company = input('\\n**Target**\\nPlease let DumbResearch know, on which company you are conducting desktop research')\n",
    "    company_context = input('\\n**Target description**\\nPlease let DumbResearch know more about the company, i.e. what industry, geographies and if you want it to pay particular attention to anything or exclude something in its research!\\n')\n",
    "    result = parse_semicolon_csv(competitors_with_chatGPT(company,company_context))\n",
    "    return result\n",
    "\n",
    "\n",
    "def competitors_with_chatGPT(company, company_context):\n",
    "    \"\"\"\n",
    "    Sends chunks of website content to OpenAI's GPT API for parsing based on a description.\n",
    "    \"\"\"\n",
    "\n",
    "    # Loop through chunks and get responses\n",
    "    parsed_results = []\n",
    "    template = (\n",
    "        f'You are tasked with finding the competitors of a given company called {company}, with the below context provided: {company_context}.'\n",
    "        'Please follow these instructions carefully: \\n\\n'\n",
    "        ' 1. ** Extract Information** : Only extract the information that directly matches the provided description above'\n",
    "        ' 2. ** Volume** : Find at least 10 competitors for each requests.'\n",
    "        ' 3. ** Empty Response** : If no information matches the description return to an empty string'\n",
    "        ' 4. ** Direct Data** : Your response should contain only data that is explicitly requested, with no other text.'\n",
    "        ' 5. ** Format** : **Single Table**: Output exactly one table, no extra lines or text.'\n",
    "                        '  - Use semicolons (`;`) to separate columns.'\n",
    "                        '  - Properly quote cells with (\"\") if they contain semicolons or commas.'\n",
    "                        '  - If a cell has no data, use `empty`.'\n",
    "                        '  - Columns are the 1) respective competitors (\"Competitor\") 2) the industry they are in (\"Industry\") 3) the link to their website (\"Website\")'\n",
    "        )\n",
    "    prompt = template\n",
    "    print(f\"Finding competitors of {company}...\")\n",
    "\n",
    "    try:\n",
    "        response = run_chatgpt(prompt, model = 'gpt-4o')\n",
    "        parsed_results.append(response.choices[0].message.content)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing chunk {i}: {e}\")\n",
    "        parsed_results.append(\"\")  # Append an empty string if there's an error\n",
    "\n",
    "    initial_result = \"\\n\".join(parsed_results)\n",
    "\n",
    "    return initial_result\n",
    "\n",
    "def competitor_search_workflow():\n",
    "    result = find_competitors()\n",
    "    \n",
    "    # Display found competitors\n",
    "    for i, link in enumerate(result['Website']):\n",
    "        print(f\"{i}: {link}\")\n",
    "        \n",
    "    # Ask the user for additional competitors\n",
    "    user_input = input(\n",
    "        \"\\nThese are the competitors DumbResearch found. \"\n",
    "        \"Do you have any additional players you would like to add to the search? \"\n",
    "        \"Please add their respective websites, separated by a comma:\\n\"\n",
    "    )\n",
    "    add_players = [str(x.strip().lower().rstrip(\"/\")) for x in user_input.split(\",\") if x.strip()]\n",
    "    \n",
    "    # Add new competitors to the result DataFrame\n",
    "    for i in add_players:\n",
    "        new_row = {'Competitor': None, 'Industry': None, 'Website': i}\n",
    "        result = pd.concat([result, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    \n",
    "    # Display the updated list of competitors\n",
    "    for i, link in enumerate(result['Website']):\n",
    "        print(f\"{i}: {link}\")\n",
    "    \n",
    "    # Ask the user to select competitors to keep\n",
    "    user_input = input(\n",
    "        \"\\nThis is the current set of competitors. \"\n",
    "        \"Select the indexes of competitors you want to keep, separated by commas:\\n> \"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Convert the input string into a list of integers\n",
    "        indexes = [int(x.strip()) for x in user_input.split(\",\") if x.strip().isdigit()]\n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Please enter a comma-separated list of numbers.\")\n",
    "        return {}\n",
    "    \n",
    "    # Validate indexes and filter the selected competitors\n",
    "    chosen_competitors = result.iloc[indexes].reset_index(drop=True) if indexes else pd.DataFrame()\n",
    "    \n",
    "    return chosen_competitors\n",
    "\n",
    "def search_research_workflow():\n",
    "    competitor_set = competitor_search_workflow()\n",
    "    print(f'Now looking at the websites of your competitor set {competitor_set['Website']}')\n",
    "    output = dumbresearch_workflow(competitor_set['Website'])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "b45e9b67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Please let DumbResearch know, on which company you are conducting desktop research Myra Securities\n",
      "\n",
      "Please let DumbResearch know more about the company, i.e. what industry, geographies and if you want it to pay particular attention to anything or exclude something in its research!\n",
      " German cybersecurity company focused on DDoS, please limit to competitors serving the german market\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding competitors of Myra Securities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-29 10:28:43.739 INFO    httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: https://www.link11.com\n",
      "1: https://www.secucloud.com\n",
      "2: https://www.nfon.com\n",
      "3: https://www.rohde-schwarz.com\n",
      "4: https://www.avira.com\n",
      "5: https://www.f-secure.com\n",
      "6: https://www.trendmicro.com\n",
      "7: https://www.bitdefender.com\n",
      "8: https://www.mcafee.com\n",
      "9: https://www.kaspersky.com\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "These are the competitors DumbResearch found. Do you have any additional players you would like to add to the search? Please add their respective websites, separated by a comma:\n",
      " 0,2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: https://www.link11.com\n",
      "1: https://www.secucloud.com\n",
      "2: https://www.nfon.com\n",
      "3: https://www.rohde-schwarz.com\n",
      "4: https://www.avira.com\n",
      "5: https://www.f-secure.com\n",
      "6: https://www.trendmicro.com\n",
      "7: https://www.bitdefender.com\n",
      "8: https://www.mcafee.com\n",
      "9: https://www.kaspersky.com\n",
      "10: 0\n",
      "11: 2\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "This is the current set of competitors. Select the indexes of competitors you want to keep, separated by commas:\n",
      ">  0,2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now looking at the websites of your competitor set   Competitor       Industry                 Website\n",
      "0     Link11  Cybersecurity  https://www.link11.com\n",
      "1       NFON  Cybersecurity    https://www.nfon.com\n",
      "Here are the links to explore:\n",
      "\n",
      "0: https://www.link11.com/en\n",
      "1: https://www.link11.com/en/#three-pillars-for-security-amp-performance\n",
      "2: https://www.link11.com/en/solutions/network-security/infrastructure-ddos-protection/\n",
      "3: https://www.link11.com/en/solutions/network-security/cloud-insights/\n",
      "4: https://www.link11.com/en/solutions/web-protection/web-ddos-protection/\n",
      "5: https://www.link11.com/en/solutions/web-protection/bot-management/\n",
      "6: https://www.link11.com/en/solutions/web-protection/zero-touch-waf/\n",
      "7: https://www.link11.com/en/solutions/web-protection/api-protection/\n",
      "8: https://www.link11.com/en/solutions/web-performance/secure-cdn/\n",
      "9: https://www.link11.com/en/solutions/web-performance/secure-dns/\n",
      "10: https://www.link11.com/en/services/\n",
      "11: https://www.link11.com/en/verticals/hosting-protection/\n",
      "12: https://www.link11.com/en/verticals/logistic-protection/\n",
      "13: https://www.link11.com/en/verticals/banking-finance/\n",
      "14: https://www.link11.com/en/verticals/e-commerce/\n",
      "15: https://www.link11.com/en/verticals/utilities/\n",
      "16: https://www.link11.com/en/verticals/online-gaming/\n",
      "17: https://www.link11.com/en/verticals/media/\n",
      "18: https://www.link11.com/en/verticals/public-sector/\n",
      "19: https://www.link11.com/en/benchmark/\n",
      "20: https://www.link11.com/en/customers/\n",
      "21: https://www.link11.com/en/ressources\n",
      "22: https://www.link11.com/en/blog/\n",
      "23: https://www.link11.com/en/glossary/\n",
      "24: https://www.link11.com/en/blog/press/\n",
      "25: https://www.link11.com/en/downloads/\n",
      "26: https://www.link11.com/en/webinars-videos/\n",
      "27: https://www.link11.com/en/blog/webinars_events/\n",
      "28: https://www.link11.com/en/about-link11/\n",
      "29: https://www.link11.com/en/about-link11/\n",
      "30: https://www.link11.com/en/solutions/ddos-protection/\n",
      "31: https://www.link11.com/en/partner/\n",
      "32: https://www.link11.com/en/career/\n",
      "33: https://www.link11.com/en/go-green/\n",
      "34: https://www.link11.com/en/contact/\n",
      "35: https://www.link11.com/en/\n",
      "36: https://www.link11.com/de/\n",
      "37: https://webgui.link11.com/\n",
      "38: https://www.link11.com/en/emergency/\n",
      "39: https://www.link11.com/en/contact/\n",
      "40: https://www.link11.com/\n",
      "41: https://www.link11.com/en/contact/\n",
      "42: https://www.link11.com/en/solutions/ddos-protection/infrastructure-ddos-protection/\n",
      "43: https://www.link11.com/en/solutions/ddos-protection/web-ddos-protection/\n",
      "44: https://www.link11.com/en/solutions/web-security-suite/secure-cdn/\n",
      "45: https://www.link11.com/en/solutions/web-security-suite/bot-management/\n",
      "46: https://www.link11.com/en/solutions/web-security-suite/secure-dns/\n",
      "47: https://www.link11.com/en/solutions/web-security-suite/zero-touch-waf/\n",
      "48: https://www.youtube.com/watch?v=F8JFnzscJ50\n",
      "49: https://www.youtube.com/watch?v=sZftn6SLDRE\n",
      "50: https://www.youtube.com/watch?v=F8JFnzscJ50\n",
      "51: https://www.youtube.com/watch?v=sZftn6SLDRE\n",
      "52: https://www.link11.com/en/what-is-a-ddos-attack/\n",
      "53: https://www.link11.com/en/contact/\n",
      "54: https://www.link11.com/en\n",
      "55: https://www.linkedin.com/company/link11/\n",
      "56: https://www.instagram.com/link11com/\n",
      "57: https://www.youtube.com/@Link11com\n",
      "58: tel:+4969264929777\n",
      "59: https://www.link11.com/de/kontakt/\n",
      "60: tel:+496958004926305\n",
      "61: https://www.link11.com/de/kontakt/\n",
      "62: tel:+18181344\n",
      "63: https://www.link11.com/de/kontakt/\n",
      "64: https://www.link11.com/en/about-link11/\n",
      "65: https://www.link11.com/en/partner/\n",
      "66: https://www.link11.com/en/career/\n",
      "67: https://www.link11.com/en/blog/\n",
      "68: https://www.link11.com/en/solutions/\n",
      "69: https://www.link11.com/en/downloads/\n",
      "70: https://www.link11.com/en/blog/blog_category/press/\n",
      "71: https://www.link11.com/en/contact/\n",
      "72: https://www.link11.com/en/imprint/\n",
      "73: https://www.link11.com/en/privacy/\n",
      "74: https://www.link11.com/en/eula/\n",
      "75: https://www.link11.com\n",
      "76: https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.link11.com%2Fen%2F\n",
      "77: https://twitter.com/intent/tweet?text=Home&url=https%3A%2F%2Fwww.link11.com%2Fen%2F\n",
      "78: https://www.linkedin.com/shareArticle?mini=true&url=https%3A%2F%2Fwww.link11.com%2Fen%2F&title=Home\n",
      "79: whatsapp://send?text=Home https%3A%2F%2Fwww.link11.com%2Fen%2F\n",
      "80: https://www.link11.com/en\n",
      "81: https://www.link11.com/\n",
      "82: https://www.link11.com/en/#three-pillars-for-security-amp-performance\n",
      "83: https://www.link11.com/en/solutions/network-security/infrastructure-ddos-protection/\n",
      "84: https://www.link11.com/en/solutions/network-security/cloud-insights/\n",
      "85: https://www.link11.com/en/solutions/web-protection/web-ddos-protection/\n",
      "86: https://www.link11.com/en/solutions/web-protection/bot-management/\n",
      "87: https://www.link11.com/en/solutions/web-protection/zero-touch-waf/\n",
      "88: https://www.link11.com/en/solutions/web-protection/api-protection/\n",
      "89: https://www.link11.com/en/solutions/web-performance/secure-cdn/\n",
      "90: https://www.link11.com/en/solutions/web-performance/secure-dns/\n",
      "91: https://www.link11.com/en/services/\n",
      "92: https://www.link11.com/en/verticals/hosting-protection/\n",
      "93: https://www.link11.com/en/verticals/logistic-protection/\n",
      "94: https://www.link11.com/en/verticals/banking-finance/\n",
      "95: https://www.link11.com/en/verticals/e-commerce/\n",
      "96: https://www.link11.com/en/verticals/utilities/\n",
      "97: https://www.link11.com/en/verticals/online-gaming/\n",
      "98: https://www.link11.com/en/verticals/media/\n",
      "99: https://www.link11.com/en/verticals/public-sector/\n",
      "100: https://www.link11.com/en/benchmark/\n",
      "101: https://www.link11.com/en/customers/\n",
      "102: https://www.link11.com/en/ressources\n",
      "103: https://www.link11.com/en/blog/\n",
      "104: https://www.link11.com/en/glossary/\n",
      "105: https://www.link11.com/en/blog/press/\n",
      "106: https://www.link11.com/en/downloads/\n",
      "107: https://www.link11.com/en/webinars-videos/\n",
      "108: https://www.link11.com/en/blog/webinars_events/\n",
      "109: https://www.link11.com/en/about-link11/\n",
      "110: https://www.link11.com/en/about-link11/\n",
      "111: https://www.link11.com/en/solutions/ddos-protection/\n",
      "112: https://www.link11.com/en/partner/\n",
      "113: https://www.link11.com/en/career/\n",
      "114: https://www.link11.com/en/go-green/\n",
      "115: https://www.link11.com/en/contact/\n",
      "116: https://www.link11.com/en/\n",
      "117: https://www.link11.com/de/\n",
      "118: https://webgui.link11.com/\n",
      "119: https://www.link11.com/en/emergency/\n",
      "120: https://www.link11.com/en/contact/\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Select the indexes of links you want to explore, separated by commas:\n",
      ">  4,44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the links to explore:\n",
      "\n",
      "0: https://www.nfon.com/de\n",
      "1: https://www.nfon.com\n",
      "2: https://www.nfon.com/de/produkte/cloud-telefonie/\n",
      "3: https://www.nfon.com/de/produkte/cloud-telefonie/\n",
      "4: https://www.nfon.com/de/produkte/cloud-telefonie/cloudya\n",
      "5: https://www.nfon.com/de/produkte/endgeraete\n",
      "6: https://www.nfon.com/de/produkte/enablement/\n",
      "7: https://www.nfon.com/de/produkte/enablement/\n",
      "8: https://www.nfon.com/de/produkte/enablement/sip-trunk-flexx\n",
      "9: https://www.nfon.com/de/produkte/kundenkontakt/\n",
      "10: https://www.nfon.com/de/produkte/kundenkontakt/\n",
      "11: https://www.nfon.com/de/produkte/kundenkontakt/contact-center-hub\n",
      "12: https://www.nfon.com/de/integrations/microsoft-teams/\n",
      "13: https://www.nfon.com/de/integrations/crm-connect\n",
      "14: https://www.nfon.com/de/integrations/ncti\n",
      "15: https://www.nfon.com/de/produkte/kundenkontakt/nmonitoring-queues\n",
      "16: https://www.nfon.com/de/produkte/kundenkontakt/noperatorpanel\n",
      "17: https://www.nfon.com/de/produkte/kundenkontakt/nhospitality\n",
      "18: https://www.nfon.com/de/produkte/kundenkontakt/neorecording\n",
      "19: https://www.nfon.com/de/produkte/botario\n",
      "20: https://www.nfon.com/de/produkte/botario\n",
      "21: https://www.nfon.com\n",
      "22: https://www.nfon.com/de/solutions/gesundheit-wellness\n",
      "23: https://www.nfon.com/de/solutions/einzelhandel\n",
      "24: https://www.nfon.com/de/solutions/finanzen-versicherungen\n",
      "25: https://www.nfon.com/de/solutions/hospitality\n",
      "26: https://www.nfon.com/de/solutions/oeffentlichersektor\n",
      "27: https://www.nfon.com/de/kundenstories/\n",
      "28: https://www.nfon.com/de/kundenstories/foodist\n",
      "29: https://www.nfon.com/de/kundenstories/demeter\n",
      "30: https://www.nfon.com/de/kundenstories/financial-com\n",
      "31: https://www.nfon.com/de/kundenstories/wefapress\n",
      "32: https://www.nfon.com/de/kundenstories/analysys-mason\n",
      "33: https://www.nfon.com\n",
      "34: https://www.nfon.com/de/partner/partner-werden\n",
      "35: https://www.nfon.com/de/partner/partnerprogramm\n",
      "36: https://partners.nfon.com/\n",
      "37: https://www.nfon.com\n",
      "38: https://www.nfon.com/de/service/dokumentation/handbuecher\n",
      "39: https://www.nfon.com/de/service/downloads\n",
      "40: https://blog.nfon.com/de/hardware-updates\n",
      "41: https://blog.nfon.com/de/hardware-firmware-releases\n",
      "42: https://www.nfon.com/de/service/release-notes\n",
      "43: https://www.nfon.com\n",
      "44: https://www.nfon.com/de/produkte/cloud-telefonie/faq\n",
      "45: https://www.nfon.com/de/los-gehts/cloud-telefonie\n",
      "46: https://blog.nfon.com/de\n",
      "47: https://www.nfon.com/de/los-gehts/cloud-telephonie/lexikon\n",
      "48: https://portierung.nfon.net/\n",
      "49: https://reporting.nfon.com/\n",
      "50: https://mynfon.net/\n",
      "51: https://status.nfon.com/\n",
      "52: https://www.nfon.com\n",
      "53: https://start.cloudya.com/\n",
      "54: https://www.nfon.com\n",
      "55: https://www.nfon.com/en/\n",
      "56: https://www.nfon.com/de\n",
      "57: https://www.nfon.com/at/\n",
      "58: https://www.nfon.com/gb/\n",
      "59: https://www.nfon.com/fr/\n",
      "60: https://www.nfon.com/it/\n",
      "61: https://www.nfon.com/nl\n",
      "62: https://www.nfon.com/es/\n",
      "63: https://www.nfon.com/pt/\n",
      "64: https://www.nfon.com/hr\n",
      "65: https://www.nfon.com/pl/\n",
      "66: https://www.nfon.com/sk\n",
      "67: https://www.nfon.com/si\n",
      "68: https://www.nfon.com/hu\n",
      "69: https://www.nfon.com/ro\n",
      "70: https://www.nfon.com/cz\n",
      "71: https://www.nfon.com\n",
      "72: https://www.nfon.com\n",
      "73: tel:+49 8000 - 63 66 24\n",
      "74: tel:+49 800 63 66 555\n",
      "75: https://www.nfon.com/de/information-anfordern\n",
      "76: https://www.nfon.com/de/information-anfordern\n",
      "77: https://www.nfon.com/de/kundenstories/\n",
      "78: https://www.nfon.com/de/produkte/cloud-telefonie/\n",
      "79: https://www.nfon.com/de/produkte/enablement/\n",
      "80: https://www.nfon.com/de/produkte/kundenkontakt/\n",
      "81: https://www.nfon.com/de/produkte/botario\n",
      "82: https://www.nfon.com/de/produkte/botario\n",
      "83: https://www.nfon.com/de/produkte/botario\n",
      "84: https://www.nfon.com/de/solutions/gesundheit-wellness\n",
      "85: https://www.nfon.com/de/solutions/einzelhandel\n",
      "86: https://www.nfon.com/de/solutions/finanzen-versicherungen\n",
      "87: https://www.nfon.com/de/solutions/oeffentlichersektor\n",
      "88: https://www.nfon.com/de/information-anfordern\n",
      "89: https://blog.nfon.com/de/sicherheit-im-fokus-nfon-erhaelt-c5-testat?_gl=1*vfehyp*_gcl_aw*R0NMLjE3MzE2NzQ5MTcuQ2owS0NRaUFfOXU1QmhDVUFSSXNBQmJNU1BzTzV1a1ZFMUxVY0t2VUl6SEFPYkVNVVYxR09kVHlLU1RqY191RmVHZHUtamphcXVJZE5nSWFBcTJLRUFMd193Y0I.*_gcl_au*MTM3Mjg3MTI0Ny4xNzMwMjk0MTU3LjE5ODQ0MDQ4NTUuMTczMTA4NDA0OS4xNzMxMDg0MDQ4*_ga*MTQ3Njk4MzM2MS4xNzE0NzI3MTU3*_ga_0L7D0VJE42*MTczMTcwMDA2Mi4xMjUuMS4xNzMxNzAwMDY1LjU3LjAuNjUzNTgxNTk3\n",
      "90: https://www.nfon.com/de/information-anfordern\n",
      "91: https://www.nfon.com/de/news/veranstaltungen\n",
      "92: https://www.nfon.com/de/news/press/\n",
      "93: https://start.cloudya.com/auth/login\n",
      "94: https://portal.nfon.com/de/login\n",
      "95: https://status.nfon.com/\n",
      "96: https://corporate.nfon.com/de/\n",
      "97: https://corporate.nfon.com/de/investor-relations/ir-auf-einen-blick\n",
      "98: https://corporate.nfon.com/de/sustainability/\n",
      "99: https://corporate.nfon.com/de/karriere/\n",
      "100: https://www.nfon.com/de/rechtliches/agb-und-leistungsbeschreibung\n",
      "101: https://www.nfon.com/de/rechtliches/impressum\n",
      "102: https://www.nfon.com/de/trust-center/\n",
      "103: https://www.nfon.com/de/rechtliches/datenschutzerklaerung\n",
      "104: javascript:onclick=UC_UI.showSecondLayer\n",
      "105: https://www.linkedin.com/company/nfon\n",
      "106: https://www.facebook.com/NFONcom/\n",
      "107: https://x.com/NFONcom\n",
      "108: https://www.youtube.com/@NFONcom\n",
      "109: https://www.nfon.com/de/information-anfordern\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Select the indexes of links you want to explore, separated by commas:\n",
      ">  2,5\n",
      "\n",
      "Please let DumbResearch know:\n",
      "1. What web content it is looking at \n",
      "2. What columns you would like your research output table to have \n",
      "\n",
      "See example below: \n",
      "\"These are the solutions offered by a german cyber security player (input is provided in German), please provide a table or tables that list the respective products / solutions with important information on the respective products e.g. their descriptions, features, target customers, KPIs\"\n",
      " Products by German cybersecurity companies please look for key information, such as escriptions, features, target customers, KPIs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'https://www.link11.com': ['https://www.link11.com/en/solutions/web-protection/web-ddos-protection/', 'https://www.link11.com/en/solutions/web-security-suite/secure-cdn/'], 'https://www.nfon.com': ['https://www.nfon.com/de/produkte/cloud-telefonie/', 'https://www.nfon.com/de/produkte/endgeraete']}\n",
      "Processing https://www.link11.com/en/solutions/web-protection/web-ddos-protection/#all-possibilities-with-one-solution, 1 out of 1 links in depth level 0 for https://www.link11.com/en/solutions/web-protection/web-ddos-protection/, 1 out of 2 selected links\n",
      "Processing https://www.link11.com/en/solutions/web-security-suite/secure-cdn/#all-possibilities-with-one-solution, 1 out of 1 links in depth level 0 for https://www.link11.com/en/solutions/web-security-suite/secure-cdn/, 2 out of 2 selected links\n",
      "\n",
      "Preprocess finished in 37.91 seconds\n",
      "Processing https://www.link11.com/en/solutions/web-protection/web-ddos-protection/, 1 out of 2 datasets to process.\n",
      "Processing chunk 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-29 10:32:25.739 INFO    httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 2/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-29 10:32:26.867 INFO    httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 3/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-29 10:32:28.960 INFO    httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 4/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-29 10:32:33.012 INFO    httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing https://www.link11.com/en/solutions/web-security-suite/secure-cdn/, 2 out of 2 datasets to process.\n",
      "Processing chunk 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-29 10:33:06.662 INFO    httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 2/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-29 10:33:09.413 INFO    httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 3/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-29 10:33:11.718 INFO    httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 4/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-29 10:33:12.212 INFO    httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parsing scrape results finished in 78.96 seconds\n",
      "Processing https://www.nfon.com/de/produkte/cloud-telefonie/cloudya, 1 out of 2 links in depth level 0 for https://www.nfon.com/de/produkte/cloud-telefonie/, 1 out of 2 selected links\n",
      "Processing https://www.nfon.com/de/produkte/cloud-telefonie/faq, 2 out of 2 links in depth level 0 for https://www.nfon.com/de/produkte/cloud-telefonie/, 1 out of 2 selected links\n",
      "\n",
      "Preprocess finished in 37.91 seconds\n",
      "Processing https://www.nfon.com/de/produkte/cloud-telefonie/, 1 out of 2 datasets to process.\n",
      "Processing chunk 1/3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-29 10:34:23.704 INFO    httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 2/3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-29 10:34:25.815 INFO    httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 3/3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-29 10:34:28.825 INFO    httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing https://www.nfon.com/de/produkte/endgeraete, 2 out of 2 datasets to process.\n",
      "Processing chunk 1/3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-29 10:34:37.291 INFO    httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 2/3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-29 10:34:40.089 INFO    httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 3/3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-29 10:34:46.130 INFO    httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parsing scrape results finished in 56.01 seconds\n"
     ]
    }
   ],
   "source": [
    "result = search_research_workflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "362dfad5-2b81-49e4-8dbb-9d4e5bded9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>| Product Name     | Description                                                                                           | Features                                                                                               | Target Customers               |</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>|------------------|--------------------------...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>| Yealink T46U     | Ultimatives Kommunikation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>| Snom M430 Paket  | Umfassende Geschäftstelef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>| Product Name        | Description           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>|---------------------|-----------------------...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>| Polycom VVX 350     | IP phone suitable for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>| Product Name | Description | Features | Targ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>|--------------|-------------|----------|-----...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>| Yealink W70B | Einzellen-DECT-Lösung für kle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>| Yealink W73H | Mobilteil der neuen Generatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>| Yealink W74H | Kabelloses Mobilteil mit eleg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   | Product Name     | Description                                                                                           | Features                                                                                               | Target Customers               |\n",
       "0   |------------------|--------------------------...                                                                                                                                                                                                                    \n",
       "1   | Yealink T46U     | Ultimatives Kommunikation...                                                                                                                                                                                                                    \n",
       "2   | Snom M430 Paket  | Umfassende Geschäftstelef...                                                                                                                                                                                                                    \n",
       "3   | Product Name        | Description           ...                                                                                                                                                                                                                    \n",
       "4   |---------------------|-----------------------...                                                                                                                                                                                                                    \n",
       "5   | Polycom VVX 350     | IP phone suitable for ...                                                                                                                                                                                                                    \n",
       "6   | Product Name | Description | Features | Targ...                                                                                                                                                                                                                    \n",
       "7   |--------------|-------------|----------|-----...                                                                                                                                                                                                                    \n",
       "8   | Yealink W70B | Einzellen-DECT-Lösung für kle...                                                                                                                                                                                                                    \n",
       "9   | Yealink W73H | Mobilteil der neuen Generatio...                                                                                                                                                                                                                    \n",
       "10  | Yealink W74H | Kabelloses Mobilteil mit eleg...                                                                                                                                                                                                                    "
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['https://www.nfon.com']['https://www.nfon.com/de/produkte/endgeraete']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "6454816a-37ac-4086-9487-b952021c48ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = run_selenium('https://www.link11.com/en/solutions/web-protection/web-ddos-protection/')\n",
    "clean_content = clean_body_content(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "09011043-1c70-427e-bc87-050f3306fea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Web DDoS Protection - Link11\\nSolutions\\nNetwork Security\\nInfrastructure DDoS Protection\\nCloud Insights\\nWeb Protection\\nWeb DDoS Protection\\nBot Management\\nZero Touch WAF\\nAPI Protection\\nWeb Performance\\nSecure CDN\\nSecure DNS\\nIndustries\\nHosting\\nLogistic\\nBanking & Finance\\nE-Commerce\\nUtilities\\nOnline Gaming\\nMedia\\nPublic Sector\\nBenchmark\\nCustomers\\nResources\\nBlog\\nGlossary\\nPress\\nDownloads\\nVideos & Podcasts\\nEvents\\nAbout Link11\\nCompany\\nPatented DDoS Protection\\nPartner\\nCareer\\nCarbon Neutrality\\nContact\\nen\\nde\\nLogin\\nUnder attack?\\nContact\\nWeb DDoS Protection\\nCloud-based DDoS protection for web applications\\nAutomation ensures 24/7 protection\\nZero time to mitigate for known,\\n<\\n10 seconds for new vectors\\n4.3/5 Google Reviews\\nBook a demo\\nLearn more\\nPrecise detection\\nNo need to worry about complex attacks anymore: The system detects traffic anomalies and protects you from emerging threats in real time.\\nFull automation\\nNo work for you: manual operation is not required, and the system works fully automatically and without compromise.\\nDetailed customization\\nWhitelisting, blacklisting, enhanced logs, traffic control, and more – helpful features help you make everyday life as easy as possible.\\nBook a demo\\n* Mandatory Fields\\nYour name\\nHow can we reach you?\\nAbout your organization:\\nCountry*\\nGermany\\nAustria\\nSwitzerland\\nUnited Kingdom\\nIreland\\nUnited States\\nCanada\\nAndorra\\nUnited Arab Emirates\\nAfghanistan\\nAntigua and Barbuda\\nAnguilla\\nAlbania\\nArmenia\\nAngola\\nAntarctica\\nArgentina\\nAustralia\\nAruba\\nAland Islands\\nAzerbaijan\\nBosnia and Herzegovina\\nBarbados\\nBangladesh\\nBelgium\\nBurkina Faso\\nBulgaria\\nBahrain\\nBurundi\\nBenin\\nSaint Barthélemy\\nBermuda\\nBrunei Darussalam\\nBolivia, Plurinational State of\\nBonaire, Sint Eustatius and Saba\\nBrazil\\nBahamas\\nBhutan\\nBouvet Island\\nBotswana\\nBelarus\\nBelize\\nCocos (Keeling) Islands\\nCongo, the Democratic Republic of the\\nCentral African Republic\\nCongo\\nCote d'Ivoire\\nCook Islands\\nChile\\nCameroon\\nChina\\nColombia\\nCosta Rica\\nCuba\\nCape Verde\\nCuraçao\\nChristmas Island\\nCyprus\\nCzech Republic\\nDjibouti\\nDenmark\\nDominica\\nDominican Republic\\nAlgeria\\nEcuador\\nEstonia\\nEgypt\\nWestern Sahara\\nEritrea\\nSpain\\nEthiopia\\nFinland\\nFiji\\nFalkland Islands (Malvinas)\\nFaroe Islands\\nFrance\\nGabon\\nGrenada\\nGeorgia\\nFrench Guiana\\nGuernsey\\nGhana\\nGibraltar\\nGreenland\\nGambia\\nGuinea\\nGuadeloupe\\nEquatorial Guinea\\nGreece\\nSouth Georgia and the South Sandwich Islands\\nGuatemala\\nGuinea-Bissau\\nGuyana\\nHong Kong\\nHeard Island and McDonald Islands\\nHonduras\\nCroatia\\nHaiti\\nHungary\\nIndonesia\\nIsrael\\nIsle of Man\\nIndia\\nBritish Indian Ocean Territory\\nIraq\\nIran\\nIceland\\nItaly\\nJersey\\nJamaica\\nJordan\\nJapan\\nKenya\\nKyrgyzstan\\nCambodia\\nKiribati\\nComoros\\nSaint Kitts and Nevis\\nKorea, Democratic People's Republic of\\nSouth Korea\\nKuwait\\nCayman Islands\\nKazakhstan\\nLao People's Democratic Republic\\nLebanon\\nSaint Lucia\\nLiechtenstein\\nSri Lanka\\nLiberia\\nLesotho\\nLithuania\\nLuxembourg\\nLatvia\\nLibyan Arab Jamahiriya\\nMorocco\\nMonaco\\nMoldova, Republic of\\nMontenegro\\nSaint Martin (French part)\\nMadagascar\\nMacedonia, the former Yugoslav Republic of\\nMali\\nMyanmar\\nMongolia\\nMacao\\nMartinique\\nMauritania\\nMontserrat\\nMalta\\nMauritius\\nMaldives\\nMalawi\\nMexico\\nMalaysia\\nMozambique\\nNamibia\\nNew Caledonia\\nNiger\\nNorfolk Island\\nNigeria\\nNicaragua\\nNetherlands\\nNorway\\nNepal\\nNauru\\nNiue\\nNew Zealand\\nOman\\nPanama\\nPeru\\nFrench Polynesia\\nPapua New Guinea\\nPhilippines\\nPakistan\\nPoland\\nSaint Pierre and Miquelon\\nPitcairn\\nPalestinian Territory, Occupied\\nPortugal\\nParaguay\\nQatar\\nReunion\\nRomania\\nSerbia\\nRussian Federation\\nRwanda\\nSaudi Arabia\\nSolomon Islands\\nSeychelles\\nSudan\\nSweden\\nSingapore\\nSaint Helena, Ascension and Tristan da Cunha\\nSlovenia\\nSvalbard and Jan Mayen\\nSlovakia\\nSierra Leone\\nSan Marino\\nSenegal\\nSomalia\\nSuriname\\nSouth Sudan\\nSao Tome and Principe\\nEl Salvador\\nSint Maarten (Dutch part)\\nSyria\\nSwaziland\\nTurks and Caicos Islands\\nChad\\nFrench Southern Territories\\nTogo\\nThailand\\nTajikistan\\nTokelau\\nTimor-Leste\\nTurkmenistan\\nTunisia\\nTonga\\nTurkey\\nTrinidad and Tobago\\nTuvalu\\nTaiwan\\nTanzania, United Republic of\\nUkraine\\nUganda\\nUruguay\\nUzbekistan\\nHoly See (Vatican City State)\\nSaint Vincent and the Grenadines\\nVenezuela, Bolivarian Republic of\\nVirgin Islands, British\\nVietnam\\nVanuatu\\nWallis and Futuna\\nSamoa\\nYemen\\nMayotte\\nSouth Africa\\nZambia\\nZimbabwe\\nWould you like to give us additional information to speed up the consultation process?\\nYes, I would like to answer further questions.\\nHow many websites are in operation?\\nHow many backend IPs are in use?\\nHow much traffic is measured in TB?\\nHow many requests are there per month?\\nWhat type of certificate do you use?\\nHow big is your network? (e.g. /24)\\nHow can we reach you?\\nMessage\\nLoading...\\nBy sending this form I confirm that I have read and understood the\\nprivacy policy\\n.*\\nAll possibilities\\nwith one solution\\nDDoS attacks continue to increase and still cause great damage today. In addition to the frequency, the complexity and duration of an attack cause major problems for the defense. Therefore, the deployed solution should intervene precisely and quickly to best protect you from threats and high costs due to downtime.\\nGuaranteed protection\\nWith Web DDoS Protection, you’ll be protected by a system that, thanks to artificial intelligence, effectively stops attacks on layers 3, 4, and 7. You’ll also benefit from numerous algorithms and heuristics that monitor and evaluate events at the application layer. With this combination, you can count on guaranteed mitigation of the attack within the shortest possible time.\\nOur system analyzes the typical traffic patterns of your web applications and identifies any anomalies that deviate from the “normal” or appear suspicious. This proactive approach ensures your protection not only against known threats but also against new and unknown ones.\\nMore focus on your core business\\nOur DDoS Protection makes your job as easy as possible. That’s why the security solution’s detection and mitigation tools work entirely without manual intervention. Attacks are detected and mitigated in real-time without you having to interact with the protection. This ensures that you and your applications are protected around the clock, at any time of day.\\nThis automated security saves time and money and makes it even easier for you to focus on what matters most. Another advantage is that you don’t need to contact us in the event of an attack. Our system already knows and has taken all the necessary steps to mitigate the threat. Your everyday business can, therefore, continue as if nothing had happened.\\nExactly the way you need it\\nIndividual settings help you tailor the system ideally to your needs – our Web DDoS Protection offers just that. Provide the solution with your own certificate or use one from us, set up TCP port forwarding, or modify the geoblocking function. The choice is entirely yours.\\nThe choices mean you don’t have to work with a rigid system that dictates what you can and can’t do. Take advantage of the flexibility and tailor your settings to the exact situation.\\nFeatures that make a difference\\nAccess Logging & Monitoring\\nOur comprehensive access logs and interactive dashboard visualizations give unparalleled transparency and detailed insights into your network’s traffic patterns. Our access logs meticulously record every connection, offering a granular view of requester activity during regular operations and amidst attack scenarios.\\nBut we don’t stop there – our user-friendly dashboards transform this data into actionable visual representations, making it effortless for you to monitor, analyze, and strategize your defense. Trust is built on transparency, and our access logs and dashboards empower you with the knowledge you need to stay informed and secure.\\nFlexible IP & Geoblocking\\nShape your defense strategy to perfection with our customizable IP, Geo, and ASN Blocking Algorithms, offering you the ultimate control over your security measures. These dynamic algorithms allow you to finely adjust your protection, ensuring a harmonious balance between robust security and reducing false positives to a minimum.\\nWhether you need to block specific IPs, regions, or ASNs (Autonomous System Numbers), our comprehensive suite of blocking options allows you to create a tailored security solution that perfectly aligns with your organization’s unique requirements thanks to Whitelisting.\\nCaptcha Defense for suspicious IPs\\nSafeguard your network against suspicious IPs with our robust Captcha verification system, effectively filtering out automated and bot traffic while allowing legitimate users to access your services seamlessly. What sets us apart is our commitment to privacy and data protection.\\nWith this added layer of security, you can confidently protect your network while respecting user privacy and legal requirements.\\nEnhanced Web Traffic Management\\nElevate your network’s performance with an array of advanced features, including Redirects, Origin Load Balancing, and Origin Timeouts. Redirects efficiently steer unencrypted HTTP traffic towards secure HTTPS connections at the edge, enhancing data security. Meanwhile, Origin Load Balancing distributes incoming traffic intelligently across multiple servers within your architecture, ensuring optimal resource utilization and minimal latency.\\nFinally, Origin Timeouts empowers you to set precise connection and read timeout values, preventing requests from exceeding defined limits and enhancing overall network efficiency. These versatile tools collectively optimize traffic distribution and help you achieve and maintain peak performance for your online services.\\nEasy to use, powerful in the result\\nEverything at a glance: The dashboard shows key metrics, threat data, attacks averted, and data on bandwidth saved or traffic consumed. The flexibility of the data display is particularly noteworthy, as historical data can also be displayed via a data picker.\\n1\\nReporting allows creating individual reports and scheduled reports, which can also be exported to PDF. In addition, there is function to send reports automatically at specified times.\\n2\\nUser management gives administrators a detailed overview. User rights and security information can thus be conveniently checked and assigned. Details, such as the time of the last password change, and the activation of the two-factor authentication procedure can be found here.\\n3\\nAlarming: The notification frequency can be set in the contact settings. This allows customization so that users can be selected by products or areas of responsibility, for example. This way, only selected people can receive notifications and communication becomes more efficient.\\n4\\nEnhanced password management: Alphanumeric passwords and a configurable password length ensure that access is and remains secure. You can also use the WebGUI to set the maximum lifespan of passwords, prevent the reuse of older passwords and set a predefined limit for failed login attempts.\\n5\\nWhy you can rely on\\nLink11\\nFast & precise protection\\nWe protect more than two million assets of well-known customers worldwide. Our technology has more than proven itself during that process.\\nEasy to set-up\\nOur solutions are easy to integrate into any set-up. It is important for us that the effort for you is reduced to an absolute minimum.\\n24/7 Customer service\\nFor us, being there for you at any time is important. That’s why we offer 24/7 customer service in English and German to assist you in all topics.\\nCertified & qualified\\nFully compliant according to the strict EU data privacy laws. Also, ISO 27001 certified and officially qualified for the CRITIS sector by the Federal Office for Information Security (BSI).\\nEasily expanded\\nAlthough Web DDoS Protection already provides a wide range of security, you can easily extend the protection standard with additional services.\\n“A failure of our systems would not only have consequences for us, but also for the many platform participants. At Link11, we are glad that they work reliably, quickly, openly and transparently. That reinforces trust in this service provider.”\\nStefan Feller\\nDepartment head IT infrastructure\\nPharma mall\\nImportant Certificates & Partnerships\\nWould you like to learn more?\\nPowerful Web Application Protection\\nTogether, we will create a customized solution for protecting your web applications. Our security experts will happily support you and advise you without obligation on the benefits of our Link11 solutions for your company.\\nBook a demo\\nBook a demo\\n* Mandatory Fields\\nYour name\\nHow can we reach you?\\nAbout your organization:\\nCountry*\\nGermany\\nAustria\\nSwitzerland\\nUnited Kingdom\\nIreland\\nUnited States\\nCanada\\nAndorra\\nUnited Arab Emirates\\nAfghanistan\\nAntigua and Barbuda\\nAnguilla\\nAlbania\\nArmenia\\nAngola\\nAntarctica\\nArgentina\\nAustralia\\nAruba\\nAland Islands\\nAzerbaijan\\nBosnia and Herzegovina\\nBarbados\\nBangladesh\\nBelgium\\nBurkina Faso\\nBulgaria\\nBahrain\\nBurundi\\nBenin\\nSaint Barthélemy\\nBermuda\\nBrunei Darussalam\\nBolivia, Plurinational State of\\nBonaire, Sint Eustatius and Saba\\nBrazil\\nBahamas\\nBhutan\\nBouvet Island\\nBotswana\\nBelarus\\nBelize\\nCocos (Keeling) Islands\\nCongo, the Democratic Republic of the\\nCentral African Republic\\nCongo\\nCote d'Ivoire\\nCook Islands\\nChile\\nCameroon\\nChina\\nColombia\\nCosta Rica\\nCuba\\nCape Verde\\nCuraçao\\nChristmas Island\\nCyprus\\nCzech Republic\\nDjibouti\\nDenmark\\nDominica\\nDominican Republic\\nAlgeria\\nEcuador\\nEstonia\\nEgypt\\nWestern Sahara\\nEritrea\\nSpain\\nEthiopia\\nFinland\\nFiji\\nFalkland Islands (Malvinas)\\nFaroe Islands\\nFrance\\nGabon\\nGrenada\\nGeorgia\\nFrench Guiana\\nGuernsey\\nGhana\\nGibraltar\\nGreenland\\nGambia\\nGuinea\\nGuadeloupe\\nEquatorial Guinea\\nGreece\\nSouth Georgia and the South Sandwich Islands\\nGuatemala\\nGuinea-Bissau\\nGuyana\\nHong Kong\\nHeard Island and McDonald Islands\\nHonduras\\nCroatia\\nHaiti\\nHungary\\nIndonesia\\nIsrael\\nIsle of Man\\nIndia\\nBritish Indian Ocean Territory\\nIraq\\nIran\\nIceland\\nItaly\\nJersey\\nJamaica\\nJordan\\nJapan\\nKenya\\nKyrgyzstan\\nCambodia\\nKiribati\\nComoros\\nSaint Kitts and Nevis\\nKorea, Democratic People's Republic of\\nSouth Korea\\nKuwait\\nCayman Islands\\nKazakhstan\\nLao People's Democratic Republic\\nLebanon\\nSaint Lucia\\nLiechtenstein\\nSri Lanka\\nLiberia\\nLesotho\\nLithuania\\nLuxembourg\\nLatvia\\nLibyan Arab Jamahiriya\\nMorocco\\nMonaco\\nMoldova, Republic of\\nMontenegro\\nSaint Martin (French part)\\nMadagascar\\nMacedonia, the former Yugoslav Republic of\\nMali\\nMyanmar\\nMongolia\\nMacao\\nMartinique\\nMauritania\\nMontserrat\\nMalta\\nMauritius\\nMaldives\\nMalawi\\nMexico\\nMalaysia\\nMozambique\\nNamibia\\nNew Caledonia\\nNiger\\nNorfolk Island\\nNigeria\\nNicaragua\\nNetherlands\\nNorway\\nNepal\\nNauru\\nNiue\\nNew Zealand\\nOman\\nPanama\\nPeru\\nFrench Polynesia\\nPapua New Guinea\\nPhilippines\\nPakistan\\nPoland\\nSaint Pierre and Miquelon\\nPitcairn\\nPalestinian Territory, Occupied\\nPortugal\\nParaguay\\nQatar\\nReunion\\nRomania\\nSerbia\\nRussian Federation\\nRwanda\\nSaudi Arabia\\nSolomon Islands\\nSeychelles\\nSudan\\nSweden\\nSingapore\\nSaint Helena, Ascension and Tristan da Cunha\\nSlovenia\\nSvalbard and Jan Mayen\\nSlovakia\\nSierra Leone\\nSan Marino\\nSenegal\\nSomalia\\nSuriname\\nSouth Sudan\\nSao Tome and Principe\\nEl Salvador\\nSint Maarten (Dutch part)\\nSyria\\nSwaziland\\nTurks and Caicos Islands\\nChad\\nFrench Southern Territories\\nTogo\\nThailand\\nTajikistan\\nTokelau\\nTimor-Leste\\nTurkmenistan\\nTunisia\\nTonga\\nTurkey\\nTrinidad and Tobago\\nTuvalu\\nTaiwan\\nTanzania, United Republic of\\nUkraine\\nUganda\\nUruguay\\nUzbekistan\\nHoly See (Vatican City State)\\nSaint Vincent and the Grenadines\\nVenezuela, Bolivarian Republic of\\nVirgin Islands, British\\nVietnam\\nVanuatu\\nWallis and Futuna\\nSamoa\\nYemen\\nMayotte\\nSouth Africa\\nZambia\\nZimbabwe\\nWould you like to give us additional information to speed up the consultation process?\\nYes, I would like to answer further questions.\\nHow many websites are in operation?\\nHow many backend IPs are in use?\\nHow much traffic is measured in TB?\\nHow many requests are there per month?\\nWhat type of certificate do you use?\\nHow big is your network? (e.g. /24)\\nHow can we reach you?\\nMessage\\nLoading...\\nBy sending this form I confirm that I have read and understood the\\nprivacy policy\\n.*\\nModal 2\\nDeutschland (Hauptsitz)\\nLindleystraße 12\\n60314 Frankfurt\\n+49 69\\n5800492677\\nKontakt\\nUK & International\\n+49 69 580 049 263 05\\nKontakt\\nNordamerika\\n+1 888 818 1344\\nKontakt\\nAbout Link11\\nPartner\\nCareer\\nBlog\\nSolutions\\nDownloads\\nPress\\nContact\\nImprint\\nPrivacy Policy\\nEULA\\nGeneric selectors\\nExact matches only\\nSearch in title\\nSearch in content\\nPost Type Selectors\\nX\\nFacebook\\nTwitter\\nLinkedIn\\nWhatsapp\""
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "74492cb3-3358-4aff-83b6-99cac0def0cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[229], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43minitialize_dumbresearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[225], line 442\u001b[0m, in \u001b[0;36minitialize_dumbresearch\u001b[0;34m(players)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minitialize_dumbresearch\u001b[39m(players \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 442\u001b[0m     domains_selected \u001b[38;5;241m=\u001b[39m \u001b[43muser_selects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplayers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m     parse_description \u001b[38;5;241m=\u001b[39m user_task()\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m domains_selected, parse_description\n",
      "Cell \u001b[0;32mIn[225], line 427\u001b[0m, in \u001b[0;36muser_selects\u001b[0;34m(players)\u001b[0m\n\u001b[1;32m    424\u001b[0m     domains\u001b[38;5;241m.\u001b[39mextend(chosen_links)\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     domains \u001b[38;5;241m=\u001b[39m \u001b[43mselect_topics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m domain_links \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m domain \u001b[38;5;129;01min\u001b[39;00m domains:\n",
      "Cell \u001b[0;32mIn[225], line 388\u001b[0m, in \u001b[0;36mselect_topics\u001b[0;34m()\u001b[0m\n\u001b[1;32m    385\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m^(https?:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m/)?([\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw.-]+)+(:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+)?(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m/[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw._-]*)*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m/?$\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m re\u001b[38;5;241m.\u001b[39mmatch(pattern, url)\n\u001b[0;32m--> 388\u001b[0m website_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mPlease paste the websites you\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43md like to explore, separated by commas: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m website_input\u001b[38;5;241m.\u001b[39mstrip():\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo websites entered. Please try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/ipykernel/kernelbase.py:1177\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[1;32m   1174\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[1;32m   1175\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1176\u001b[0m     )\n\u001b[0;32m-> 1177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/ipykernel/kernelbase.py:1219\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1216\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1218\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m-> 1219\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1221\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "initialize_dumbresearch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d09bb9f",
   "metadata": {},
   "source": [
    "# User pastes in links they want to look at. Programm takes links and asks \n",
    "* which part of the website the user wants to look at\n",
    "* for each of the subsection what they want the output to look like and a description\n",
    "* where they want the output to be saved\n",
    "\n",
    "# Program runs for each website, creates the tabular output for each of the websites subsections (e.g. product, locations)\n",
    "\n",
    "# Tabular output is saved to the specified location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56c1de4",
   "metadata": {},
   "source": [
    "Appendix\n",
    "\n",
    "parse_description = ('These are the solutions offered by a german cyber security player (input is provided in German), please provide a table or tables that list the respective products / solutions with important information on the respective products e.g. their descriptions, features, target customers, KPIs')\n",
    "\n",
    "#Function to extract deeper-level headlines\n",
    "def extract_headlines_with_depth(links, depth):\n",
    "    headlines = set()\n",
    "    for link in links:\n",
    "        try:\n",
    "            html = run_selenium(domain)\n",
    "            time.sleep(10)\n",
    "\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            \n",
    "            for a_tag in soup.find_all('a', href=True):\n",
    "                # Resolve relative URLs\n",
    "                full_url = urljoin(link, a_tag['href'])\n",
    "                parsed = urlparse(full_url)\n",
    "                path_parts = parsed.path.strip('/').split('/')\n",
    "                if len(path_parts) == depth:\n",
    "                    headlines.append(full_url)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error visiting {full_url}: {e}\")\n",
    "            parsed = urlparse(link)\n",
    "            path_parts = parsed.path.strip('/').split('/')\n",
    "            if len(path_parts) == depth:\n",
    "                headline = \"/\".join(path_parts[:depth])\n",
    "                headlines.add(headline)\n",
    "    return sorted(headlines)\n",
    "\n",
    "\n",
    "def extract_second_level_headlines(links):\n",
    "    # Parse URLs and extract paths\n",
    "    headlines = set()  # Use a set to avoid duplicates\n",
    "    for link in links:\n",
    "        parsed = urlparse(link)\n",
    "        path_parts = parsed.path.strip('/').split('/')\n",
    "\n",
    "        # Match second-level paths (e.g., /solutions/, /locations/)\n",
    "        headline = \"/\".join(path_parts[:1])\n",
    "        headlines.add(headline)\n",
    "\n",
    "    return sorted(headlines)\n",
    "    \n",
    "def get_select_data(headlines, domain,depth = 3):\n",
    "    domain = domain\n",
    "    subpage_links = set(get_all_links(domain))  # Assuming this fetches all sub-links from the domain\n",
    "    \n",
    "    # Dictionary to store concatenated text for each key\n",
    "    content_dict = defaultdict(str)\n",
    "\n",
    "    # Fetch and process links\n",
    "    urls = {}\n",
    "    for page in headlines:\n",
    "        # Match URLs for the current page\n",
    "        urls[page] = re_match_second_level_headlines(page, domain, subpage_links)\n",
    "        for url in urls[page]:  # Iterate over the URLs for the current page\n",
    "            if not is_valid_url(url):  # Validate URL before scraping\n",
    "                print(f\"Invalid URL skipped: {url}\")\n",
    "                continue\n",
    "\n",
    "            print(f\"Scraping URL: {url}\")\n",
    "            result = run_selenium(url)  # Scrape website content\n",
    "            body_content = extract_body_content(result)  # Extract body content\n",
    "            cleaned_content = clean_body_content(body_content)  # Clean the content\n",
    "\n",
    "            # Concatenate the cleaned content to the respective key in the dictionary\n",
    "            content_dict[page] += cleaned_content + \" \"  # Add a space between concatenated content\n",
    "\n",
    "    return content_dict\n",
    "    \n",
    "    \n",
    "\n",
    "def re_match_second_level_headlines(headline, domain, links_to_visit):\n",
    "    matching_urls = []\n",
    "    headline_url = urljoin(domain, headline)\n",
    "    matching_urls.extend([url for url in links_to_visit if url.startswith(headline_url)])\n",
    "    return matching_urls\n",
    "    \n",
    "    \n",
    "        refinement_prompt = (f'This is the output from an LLM that has been fed multiple chunks of information: {initial_result}.'\n",
    "                     'Please clean this output up by following these instructions carefully: \\n\\n'\n",
    "                     '1. Format: The output will likely be in multiple tables, please condense all output into one table. IMPORTANT: “Output the table as valid CSV with exactly the same number of columns for all rows (have fill value \"empty\" if there is not input for a given cell), no extra lines, and properly quoted cells if they contain commas. Use a semicolon to seperate cells instead of a comma”'\n",
    "                     '2. No duplication: The table you create should not contain duplicate rows, there should only be one row with relevant information for each e.g. product, location, customer etc'\n",
    "                     '3. If the tables you receive have multiple different categories (e.g. solutions, locations, customers) still include them into one table and add a columns called \"type\" to your table that captures this information'\n",
    "                     )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def parse_with_chatgpt(dom_chunks, parse_description):\n",
    "    \"\"\"\n",
    "    Sends chunks of website content to OpenAI's GPT API for parsing based on a description.\n",
    "    \"\"\"\n",
    "\n",
    "    template = (\n",
    "        f'You are tasked with extracting specific information from the following text content: {dom_chunks}.'\n",
    "        'Please follow these instructions carefully: \\n\\n'\n",
    "        f' 1. ** Extract Information** : Only extract the information that directly matches the provided description {parse_description}'\n",
    "        ' 2. ** No Extra Content** : Do not include any additional text, comments or explanations in your response.'\n",
    "        ' 3. ** Empty Response** : If no information matches the description return to an empty string'\n",
    "        ' 4. ** Direct Data** : Your response should contain only data that is explicitly requested, with no other text.'\n",
    "        ' 5. ** Format** : **Single Table**: Output exactly one table, no extra lines or text.'\n",
    "                        '  - Use semicolons (`;`) to separate columns.'\n",
    "                        '  - Properly quote cells with (\"\") if they contain semicolons or commas.'\n",
    "                        '  - If a cell has no data, use `empty`.'\n",
    "        )\n",
    "\n",
    "    # Loop through chunks and get responses\n",
    "    parsed_results = []\n",
    "    for i, chunk in enumerate(dom_chunks, start=1):\n",
    "        prompt = templa\n",
    "te.format(dom_chunks=chunk, parse_description=parse_description)\n",
    "        print(f\"Processing chunk {i}/{len(dom_chunks)}...\")\n",
    "\n",
    "        try:\n",
    "            response = run_chatgpt(prompt)\n",
    "            \n",
    "            if isinstance(response, list):\n",
    "                parsed_results.append(response[0].choices[0].message.content)\n",
    "            else:\n",
    "                parsed_results.append(response.choices[0].message.content)\n",
    "\n",
    "            # Extract the content of the assistant's reply\n",
    "            parsed_results.append(response[0].choices[0].message.content)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing chunk {i}: {e}\")\n",
    "            parsed_results.append(\"\")  # Append an empty string if there's an error\n",
    "\n",
    "    final_result = []\n",
    "\n",
    "    initial_result = \"\\n\".join(parsed_results)\n",
    "\n",
    "    refinement_prompt = (f'This is the output from an LLM that has been fed multiple chunks of information: {initial_result}. Please merge them into a single CSV table with these requirements:'\n",
    "                        '1. **Single Table**: Output exactly one table, no extra lines or text.'\n",
    "                        '2. **Format**:'\n",
    "                        '   - Use semicolons (`;`) to separate columns.'\n",
    "                        '   - Properly quote cells with (\"\") if they contain semicolons or commas.'\n",
    "                        '   - If a cell has no data, use `empty`.'\n",
    "                        '3. **Columns**:'\n",
    "\n",
    "                        '   - All rows must have the same number of columns.'\n",
    "                        '   - No duplicate rows.'\n",
    "                        '   - If the data covers multiple categories (e.g. solutions, locations, customers), add a column named `\"Type\"` to capture the category.'\n",
    "                        '4. **No Duplicates**: Merge repeated rows or near-identical information into a single row.'\n",
    "                        '5. **Final Output**:'\n",
    "                        '   - No code fences or markdown.'\n",
    "                        '   - Strictly the CSV text (with one header row).')\n",
    "\n",
    "    if len(initial_result) > 12000:\n",
    "        dom_chunks = split_dom_content(initial_result)\n",
    "        for i, chunk in enumerate(dom_chunks,start=1):\n",
    "            prompt_02 = refinement_prompt.format(initial_result=chunk)\n",
    "            print(f\"Processing refinement chunk {i}/{len(dom_chunks)}...\")\n",
    "            try:\n",
    "                response = run_chatgpt(prompt_02)\n",
    "                if isinstance(response, list):\n",
    "                    final_result.append(response[0].choices[0].message.content)\n",
    "                else:\n",
    "                    final_result.append(response.choices[0].message.content)\n",
    "\n",
    "                # Extract the content of the assistant's reply\n",
    "                final_result.append(response[0].choices[0].message.content)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing refinement chunk {i}: {e}\")\n",
    "                final_result.append(\"\")  # Append an empty string if there's an error\n",
    "\n",
    "    else:\n",
    "\n",
    "        prompt_02 = refinement_prompt.format(initial_result=initial_result)\n",
    "        print(f\"Refining initial result...\")\n",
    "        try:\n",
    "            response = run_chatgpt(prompt_02)\n",
    "            if isinstance(response, list):\n",
    "                final_result.append(response[0].choices[0].message.content)\n",
    "            else:\n",
    "                final_result.append(response.choices[0].message.content)\n",
    "\n",
    "            # Extract the content of the assistant's reply\n",
    "            final_result.append(response[0].choices[0].message.content)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing chunk {i}: {e}\")\n",
    "            final_result.append(\"\")  # Append an empty string if there's an error\n",
    "\n",
    "    return \"\\n\".join(final_result)\n",
    "                     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
